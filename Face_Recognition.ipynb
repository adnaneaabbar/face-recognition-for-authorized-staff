{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2hLE8EkgIyhW6PwcAuxM3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnaneaabbar/face-recognition-for-authorized-staff/blob/master/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF-oI79V3vMT",
        "colab_type": "text"
      },
      "source": [
        "# Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROTJhnzbC_bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.engine.topology import Layer\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "sys.path.append(\"/face-recognition/\")\n",
        "from fr_utils import *\n",
        "from inception_blocks_v2 import *\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.set_printoptions(threshold=np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtNmV74g3fn0",
        "colab_type": "text"
      },
      "source": [
        "# Using a ConvNet  to compute encodings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXrQce721YBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9xei80i15Kb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9b18aa63-14b7-46d8-fdb6-b236752572eb"
      },
      "source": [
        "print(\"Total Params:\", FRmodel.count_params())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Params: 3743280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g486ndmi3q8k",
        "colab_type": "text"
      },
      "source": [
        "# The Triplet Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggbSIZZG2cwe",
        "colab_type": "text"
      },
      "source": [
        "These triplets are picked from our training dataset. We will write $(A^{(i)}, P^{(i)}, N^{(i)})$ to denote the $i$-th training example. \n",
        "\n",
        "We'd like to make sure that an image $A^{(i)}$ of an individual is closer to the Positive $P^{(i)}$ than to the Negative image $N^{(i)}$) by at least a margin $\\alpha$:\n",
        "\n",
        "$$\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2 + \\alpha < \\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2$$\n",
        "\n",
        "We would thus like to minimize the following \"triplet cost\":\n",
        "\n",
        "$$\\mathcal{J} = \\sum^{m}_{i=1} \\large[ \\small \\underbrace{\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2}_\\text{(1)} - \\underbrace{\\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2}_\\text{(2)} + \\alpha \\large ] \\small_+Â \\tag{3}$$\n",
        "\n",
        "Here, we are using the notation \"$[z]_+$\" to denote $max(z,0)$.  \n",
        "\n",
        "Notes:\n",
        "- The term (1) is the squared distance between the anchor \"A\" and the positive \"P\" for a given triplet; we want this to be small. \n",
        "- The term (2) is the squared distance between the anchor \"A\" and the negative \"N\" for a given triplet, we want this to be relatively large. It has a minus sign preceding it because minimizing the negative of the term is the same as maximizing that term.\n",
        "- $\\alpha$ is called the margin. It is a hyperparameter that we pick manually. We will use $\\alpha = 0.2$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKBYzWNL19xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
        "    \"\"\"\n",
        "    Implementation of the triplet loss as defined by formula (3)\n",
        "    \n",
        "    Arguments:\n",
        "    y_true -- true labels, required when we define a loss in Keras, we don't need it in this function.\n",
        "    y_pred -- python list containing three objects:\n",
        "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
        "            positive -- the encodings for the positive images, of shape (None, 128)\n",
        "            negative -- the encodings for the negative images, of shape (None, 128)\n",
        "    \n",
        "    Returns:\n",
        "    loss -- real number, value of the loss\n",
        "    \"\"\"\n",
        "    \n",
        "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
        "    \n",
        "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
        "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = -1)\n",
        "    # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
        "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = -1)\n",
        "    # Step 3: subtract the two previous distances and add alpha.\n",
        "    basic_loss = pos_dist - neg_dist + alpha\n",
        "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
        "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b42ujfmA25lv",
        "colab_type": "text"
      },
      "source": [
        "# Loading the pre-trained model\n",
        "\n",
        "### This is loading a total of 226 files of weights, an equivalent of 67Mo of data, it should take a couple of minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaC4NAVP2yQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
        "load_weights_from_FaceNet(FRmodel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuG9zOvD33MA",
        "colab_type": "text"
      },
      "source": [
        "#  Applying the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1NpTCYW38Gf",
        "colab_type": "text"
      },
      "source": [
        "##  Face Verification\n",
        "\n",
        "First we build a database containing one encoding vector for each person who is allowed to enter the office. To generate the encoding we use `img_to_encoding(image_path, model)`, which runs the forward propagation of the model on the specified image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYI6yAmD2-Wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "database = {}\n",
        "database[\"danielle\"] = img_to_encoding(\"/face-recognition/images/danielle.png\", FRmodel)\n",
        "database[\"younes\"] = img_to_encoding(\"/face-recognition/images/younes.jpg\", FRmodel)\n",
        "database[\"tian\"] = img_to_encoding(\"/face-recognition/images/tian.jpg\", FRmodel)\n",
        "database[\"andrew\"] = img_to_encoding(\"/face-recognition/images/andrew.jpg\", FRmodel)\n",
        "database[\"kian\"] = img_to_encoding(\"/face-recognition/images/kian.jpg\", FRmodel)\n",
        "database[\"dan\"] = img_to_encoding(\"/face-recognition/images/dan.jpg\", FRmodel)\n",
        "database[\"sebastiano\"] = img_to_encoding(\"/face-recognition/images/sebastiano.jpg\", FRmodel)\n",
        "database[\"bertrand\"] = img_to_encoding(\"/face-recognition/images/bertrand.jpg\", FRmodel)\n",
        "database[\"kevin\"] = img_to_encoding(\"/face-recognition/images/kevin.jpg\", FRmodel)\n",
        "database[\"felix\"] = img_to_encoding(\"/face-recognition/images/felix.jpg\", FRmodel)\n",
        "database[\"benoit\"] = img_to_encoding(\"/face-recognition/images/benoit.jpg\", FRmodel)\n",
        "database[\"arnaud\"] = img_to_encoding(\"/face-recognition/images/arnaud.jpg\", FRmodel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMJhwWPALyB8",
        "colab_type": "text"
      },
      "source": [
        "Now, when someone shows up at the building door and swipes their ID card (thus giving us their name), we can look up their encoding in the database, and use it to check if the person standing at the front door matches the name on the ID."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MogRnxccLC1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def verify(image_path, identity, database, model):\n",
        "    \"\"\"\n",
        "    Function that verifies if the person on the \"image_path\" image is \"identity\".\n",
        "    \n",
        "    Arguments:\n",
        "    image_path -- path to an image\n",
        "    identity -- string, name of the person we'd like to verify the identity. Has to be an employee who works in the office.\n",
        "    database -- python dictionary mapping names of allowed people's names (strings) to their encodings (vectors).\n",
        "    model -- our Inception model instance in Keras\n",
        "    \n",
        "    Returns:\n",
        "    dist -- distance between the image_path and the image of \"identity\" in the database.\n",
        "    door_open -- True, if the door should open. False otherwise.\n",
        "    \"\"\"\n",
        "        \n",
        "    # Step 1: Compute the encoding for the image. Use img_to_encoding() see example above.\n",
        "    encoding = img_to_encoding(image_path, model)\n",
        "    \n",
        "    # Step 2: Compute distance with identity's image\n",
        "    dist = np.linalg.norm(encoding - database[identity])\n",
        "    \n",
        "    # Step 3: Open the door if dist < 0.7, else don't open\n",
        "    if dist < 0.7:\n",
        "        print(\"It's \" + str(identity) + \". Welcome in !!!!\")\n",
        "        door_open = True\n",
        "    else:\n",
        "        print(\"It's not \" + str(identity) + \". Please go away !!!!\")\n",
        "        door_open = False\n",
        "                \n",
        "    return dist, door_open"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fdwb374JNCPU",
        "colab_type": "text"
      },
      "source": [
        "The camera takes a picture of people trying to access the office, labeled in the images folder as **camera_i.jpg**.\n",
        "\n",
        "Mr.Younes approaches the camera with his ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoCdTOi-Mx5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5522f0c3-45b5-409f-a3b1-875c75a3d5ea"
      },
      "source": [
        "verify(\"/face-recognition/images/camera_0.jpg\", \"younes\", database, FRmodel)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It's younes. Welcome in !!!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6710072, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9jvbzVaPtH3",
        "colab_type": "text"
      },
      "source": [
        "Another person approaches the camera with Mr.Younes's ID claiming to be him, let's verify her identity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY_31DZSOfav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ef8a1de5-2a5e-450c-b9c6-4951ae13c471"
      },
      "source": [
        "verify(\"/face-recognition/images/camera_2.jpg\", \"younes\", database, FRmodel)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It's not younes. Please go away !!!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9982575, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}